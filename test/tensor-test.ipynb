{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'SVD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_fix(tensor, row_len):\n",
    "            if tensor.shape[0] == row_len:\n",
    "                print(tensor.shape)\n",
    "\n",
    "                return tensor\n",
    "            elif tensor.shape[0] < row_len:\n",
    "                increased_tensor = torch.zeros((row_len, tensor.shape[1]))\n",
    "                increased_tensor[: tensor.shape[0], :] = tensor\n",
    "\n",
    "                if increased_tensor.shape[0] != row_len or increased_tensor.shape[1] != 512:\n",
    "                    print(increased_tensor.shape)\n",
    "\n",
    "                return increased_tensor\n",
    "            else:\n",
    "                if method == \"SVD\":\n",
    "                    U, S, V = torch.svd(tensor)\n",
    "                    U, S, Vh = torch.linalg.svd(tensor, full_matrices=False)\n",
    "\n",
    "                    reduced_S = torch.diag(S)[:row_len]\n",
    "                    reduced_U = U[:, :row_len]\n",
    "                    reduced_V = Vh[:row_len, :]\n",
    "\n",
    "                    return torch.mm(\n",
    "                        torch.mm(\n",
    "                            reduced_U,\n",
    "                            reduced_S\n",
    "                        ),\n",
    "                        reduced_V\n",
    "                    )\n",
    "                elif method == \"PCA\":\n",
    "                    vectors_np = torch.detach(tensor).numpy()\n",
    "\n",
    "                    pca = PCA(n_components=row_len)\n",
    "                    reduced_tensor = pca.fit_transform(vectors_np)\n",
    "                    reduced_tensor = torch.from_numpy(reduced_tensor)\n",
    "                elif method == \"NMF\":\n",
    "                    vectors_np = torch.detach(tensor).numpy()\n",
    "\n",
    "                    nmf = NMF(n_components=row_len)\n",
    "                    reduced_tensor = nmf.fit_transform(vectors_np)\n",
    "                    reduced_tensor = torch.from_numpy(reduced_tensor)\n",
    "                else:\n",
    "                    raise RuntimeError\n",
    "            \n",
    "                if reduced_tensor.shape[0] != row_len or reduced_tensor[1] != 512:\n",
    "                    print(reduced_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x6 and 5x6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((\u001b[39m10\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m dim_fix(t1, \u001b[39m5\u001b[39;49m)\u001b[39m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[23], line 23\u001b[0m, in \u001b[0;36mdim_fix\u001b[0;34m(tensor, row_len)\u001b[0m\n\u001b[1;32m     20\u001b[0m     reduced_U \u001b[39m=\u001b[39m U[:, :row_len]\n\u001b[1;32m     21\u001b[0m     reduced_V \u001b[39m=\u001b[39m Vh[:row_len, :]\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmm(\n\u001b[1;32m     24\u001b[0m         torch\u001b[39m.\u001b[39;49mmm(\n\u001b[1;32m     25\u001b[0m             reduced_U,\n\u001b[1;32m     26\u001b[0m             reduced_S\n\u001b[1;32m     27\u001b[0m         ),\n\u001b[1;32m     28\u001b[0m         reduced_V\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPCA\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     31\u001b[0m     vectors_np \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdetach(tensor)\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x6 and 5x6)"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn((10, 6))\n",
    "dim_fix(t1, 5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix:  tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "Reduced matrix:  tensor([[-0.2148,  0.8872],\n",
      "        [-0.5206,  0.2496],\n",
      "        [-0.8263, -0.3879]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a matrix\n",
    "matrix = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Perform SVD\n",
    "u, s, v = torch.svd(matrix)\n",
    "\n",
    "# Keep only the first k singular values\n",
    "k = 2\n",
    "s_k = s[:k]\n",
    "\n",
    "# Keep only the first k columns of U and the first k rows of V\n",
    "u_k = u[:, :k]\n",
    "v_k = v[:k, :]\n",
    "\n",
    "tmp = torch.mm(u_k, torch.diag(s_k))\n",
    "# Reconstruct the original matrix using only the first k singular values and the first k columns of U and V\n",
    "matrix_reduced = u[:, :k]\n",
    "\n",
    "print(\"Original matrix: \", matrix)\n",
    "print(\"Reduced matrix: \", matrix_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor(\n",
    "    [1., 2., 3.]\n",
    ").unsqueeze(0)\n",
    "#t1 = t1.view(1, 1, *t1.shape)\n",
    "\n",
    "t2 = torch.tensor(\n",
    "    [\n",
    "        [1., 2., 3.],\n",
    "        [4., 5., 6.]\n",
    "    ]\n",
    ")\n",
    "#t2 = t2.view(1, *t2.shape)\n",
    "\n",
    "t3 = torch.randn(4, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increased_tensor = torch.zeros(4, t2.shape[1])\n",
    "increased_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increased_tensor[:t2.shape[0], :] = t2\n",
    "increased_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=5000 must be between 0 and min(n_samples, n_features)=500 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Fit the PCA model to the matrix\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m pca\u001b[39m.\u001b[39;49mfit(matrix)\n\u001b[1;32m     11\u001b[0m \u001b[39m# Transform the matrix and get the first 5000 rows\u001b[39;00m\n\u001b[1;32m     12\u001b[0m matrix_transformed \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(matrix)[:, :\u001b[39m5000\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:408\u001b[0m, in \u001b[0;36mPCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[1;32m    387\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    401\u001b[0m check_scalar(\n\u001b[1;32m    402\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_oversamples,\n\u001b[1;32m    403\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_oversamples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    404\u001b[0m     min_val\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    405\u001b[0m     target_type\u001b[39m=\u001b[39mnumbers\u001b[39m.\u001b[39mIntegral,\n\u001b[1;32m    406\u001b[0m )\n\u001b[0;32m--> 408\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    409\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:483\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 483\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_full(X, n_components)\n\u001b[1;32m    484\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39marpack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_truncated(X, n_components, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:501\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    498\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mn_components=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmle\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is only supported if n_samples >= n_features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m         )\n\u001b[1;32m    500\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n_components \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_samples, n_features):\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    502\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mn_components=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m must be between 0 and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmin(n_samples, n_features)=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msvd_solver=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_components, \u001b[39mmin\u001b[39m(n_samples, n_features))\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[39melif\u001b[39;00m n_components \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(n_components, numbers\u001b[39m.\u001b[39mIntegral):\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=5000 must be between 0 and min(n_samples, n_features)=500 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "matrix = np.random.randn(5670, 500)\n",
    "\n",
    "# Initialize a PCA object with the desired number of components\n",
    "pca = PCA(n_components=5000)\n",
    "\n",
    "# Fit the PCA model to the matrix\n",
    "pca.fit(matrix)\n",
    "\n",
    "# Transform the matrix and get the first 5000 rows\n",
    "matrix_transformed = pca.transform(matrix)[:, :5000]\n",
    "\n",
    "# The shape of the matrix should now be (5000, 786)\n",
    "print(matrix_transformed.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
