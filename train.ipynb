{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SOL1archive/FinText/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets lightning --quiet"
      ],
      "metadata": {
        "id": "unBLqPGzVAmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pVgGsTiQkz7"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "import gc\n",
        "from pprint import pprint\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from datasets import Dataset, load_dataset\n",
        "\n",
        "import lightning as L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab\n",
        "google.colab.drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/projects/FinText/')"
      ],
      "metadata": {
        "id": "mAglw9BTUbt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'CommunityModel': 'beomi/KcELECTRA-base-v2022',\n",
        "    'ArticleModel': 'psyche/kolongformer-4096',\n",
        "    'num_epoch': 30,\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 2e-5,\n",
        "    'weight_decay': 1e-5\n",
        "}"
      ],
      "metadata": {
        "id": "BVjvFidGUIFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenizerMapWrapper:\n",
        "    def __init__(self):\n",
        "        self.community_tokenizer = AutoTokenizer.from_pretrained(config['CommunityModel'])\n",
        "        self.article_tokenizer = AutoTokenizer.from_pretrained(config['ArticleModel'])\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        community_texts = batch['CommunityText']\n",
        "        article_texts = batch['ArticleText']\n",
        "        if community_texts is not None:\n",
        "            for i, community_text in enumerate(community_texts):\n",
        "                if community_text is None:\n",
        "                    community_text = ' '\n",
        "                community_text = self.community_tokenizer(community_text, padding='max_length', truncation=True, max_length=512)\n",
        "                community_texts[i] = community_text\n",
        "        else:\n",
        "            community_texts = []\n",
        "\n",
        "        if article_texts is not None:\n",
        "            for i, article_text in enumerate(article_texts):\n",
        "                if article_text is None:\n",
        "                    article_text = ' '\n",
        "                article_input_ids = self.article_tokenizer(article_text, padding='max_length', truncation=True, max_length=4096)\n",
        "                article_texts[i] = article_text\n",
        "        else:\n",
        "            article_texts = []\n",
        "\n",
        "        batch['CommunityText'] = community_texts\n",
        "        batch['ArticleText'] = article_texts\n",
        "        return batch"
      ],
      "metadata": {
        "id": "uigCvUnkYKPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FinTextDataModule(L.LightningDataModule):\n",
        "    def __init__(self, tokenizer_map_wrapper, data_path='./data-dir/data-df.pkl'):\n",
        "        super().__init__()\n",
        "        self.dataset = Dataset.from_pandas(pd.read_pickle(data_path))\n",
        "        self.tokenizer_map_wrapper = tokenizer_map_wrapper\n",
        "\n",
        "    def prepare_data(self, stage=None):\n",
        "        dataset_dict = self.dataset.train_test_split(test_size=0.1, shuffle=False)\n",
        "        self.train_dataset = dataset_dict['train']\n",
        "        self.test_dataset = dataset_dict['test']\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == \"fit\":\n",
        "            self.train_dataset = self.train_dataset.map(self.tokenizer_map_wrapper, batched=False)\n",
        "        if stage == \"test\":\n",
        "            self.test_dataset = self.test_dataset.map(self.tokenizer_map_wrapper, batched=False)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset.with_format('torch'), batch_size=config['batch_size'], shuffle=False, drop_last=True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.train_dataset.with_format('torch'), batch_size=config['batch_size'], shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "oUSwfSMLT6fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c05FrjUmQk0B"
      },
      "outputs": [],
      "source": [
        "class FinTextModel(L.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.community_model = AutoModel.from_pretrained(config['CommunityModel'])\n",
        "        self.article_model = AutoModel.from_pretrained(config['ArticleModel'])\n",
        "        self.stock_lstm = nn.LSTM(input_size=4, hidden_size=10, num_layers=5, batch_first=True)\n",
        "        self.stock_linear = nn.Linear(in_features=10, out_features=4)\n",
        "        self.total_model = nn.Sequential(\n",
        "            nn.Linear(in_features=768 * 2 + 4, out_features=768 + 4),\n",
        "            nn.Linear(in_features=768 + 4, out_features=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        self.optimizer = optim.AdamW(self.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
        "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=config['num_epoch'])\n",
        "        return [self.optimizer], [self.scheduler]\n",
        "\n",
        "    def forward(self, batch, batch_idx):\n",
        "        # batch['text']: list\n",
        "        community_outputs = self.community_model(**batch['CommunityText'])\n",
        "        community_outputs = community_outputs.pooler_output\n",
        "\n",
        "        article_outputs = self.article_model(**batch['ArticleText'])\n",
        "        article_outputs = article_outputs.pooler_output\n",
        "\n",
        "        stock_input = batch['Stock']\n",
        "        stock_outputs, _ = self.stock_lstm(stock_input)\n",
        "        stock_outputs = self.stock_linear(stock_outputs)\n",
        "\n",
        "        total_input = torch.cat([community_outputs, article_outputs, stock_outputs], dim=1)\n",
        "        total_outputs = self.total_model(total_input)\n",
        "        return total_outputs\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        total_outputs = self.forward(batch, batch_idx)\n",
        "        loss = self.criterion(total_outputs, batch['Label'])\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datamodule = FinTextDataModule(TokenizerMapWrapper())"
      ],
      "metadata": {
        "id": "oWNxkTxYeFZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FinTextModel()"
      ],
      "metadata": {
        "id": "oOXpmqh8bYsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = L.Trainer(max_epochs=config['num_epoch'])"
      ],
      "metadata": {
        "id": "9Xyh2v93bgS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, datamodule=datamodule)"
      ],
      "metadata": {
        "id": "b7HG_Hp0bj7p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}